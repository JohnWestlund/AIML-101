{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b46d41",
   "metadata": {},
   "source": [
    "# An introduction to Predictive Modeling in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233ffe4-5fee-4994-8b00-057544c58354",
   "metadata": {},
   "source": [
    "This notebook walks through an example of using supervised learning on structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816a935-cb3c-49c4-8203-aa17d57fff15",
   "metadata": {},
   "source": [
    "Start by importing some basic libraries. ```%matplotlib inline``` will allow us to print some charts inside the notebook later using ```matplotlib.pyplot``` later. ```numpy``` is a library to manage large arrays. ```pandas``` is a library for data manipulation and analytics. These are the foundation for doing data preparation for AI/ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6eaa1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566d5da",
   "metadata": {},
   "source": [
    "## Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3903653",
   "metadata": {},
   "source": [
    "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
    "\n",
    "https://www.kaggle.com/c/titanic-gettingStarted\n",
    "\n",
    "We can load the CSV file as a pandas data frame in one line. The code below uses `os.path.abspath()` to find the location of this Notebook as a way or finding where the dataset is stored. This may not be portable, so you may have to update the path below with the location of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010ad60",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../datasets/titanic_train.csv')\n",
    "import os\n",
    "os.path.abspath(\"\")\n",
    "\n",
    "data = pd.read_csv(os.path.abspath(\"\") + '/data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cdfac",
   "metadata": {},
   "source": [
    "```pandas``` data frames have a HTML table representation in Jupyter Notebook.s Let's have a look at the first 6 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c2b42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1db9f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72aca15",
   "metadata": {},
   "source": [
    "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of each the columns is explained on the challenge website:\n",
    "\n",
    "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
    "\n",
    "A data frame can be converted into a numpy array by calling the `values` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c895134",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e684f7",
   "metadata": {},
   "source": [
    "However this cannot be directly fed to a scikit-learn model:\n",
    "\n",
    "\n",
    "- the target variable (survival) is mixed with the input data\n",
    "\n",
    "- some attribute such as unique ids have no predictive values for the task\n",
    "\n",
    "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
    "\n",
    "- some attribute values are missing (NaN: \"not a number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5a62e-822d-4c2e-ab88-0c30807fbdcc",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* Which fields do you think will be most predictive? (Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked)\n",
    "\n",
    "* How would you handle missing values in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c3853",
   "metadata": {},
   "source": [
    "## Predicting survival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701703ac",
   "metadata": {},
   "source": [
    "The goal of the Kaggle challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4c820",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.Survived.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d325545",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.mean(data.Survived == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b54a6",
   "metadata": {},
   "source": [
    "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74621b9b",
   "metadata": {},
   "source": [
    "pandas `Series` (columns) instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2540c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target = data.Survived.values\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e4777",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe0c9b-8711-4cc4-9073-23a77279471e",
   "metadata": {},
   "source": [
    "The Survived field is technically a Boolean. We could have told pandas that when we imported the data by passing a Schema, but we can cast the array now as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d54f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data['Survived'] = data['Survived'].astype('bool')\n",
    "target_bool = target.astype(dtype=bool)\n",
    "print(\"numpy array datatype:\", target_bool.dtype)\n",
    "print(\"numpy array values:\",target[:6])\n",
    "print(\"pandas DataFrame field values:\\n\",data['Survived'].head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1afd0",
   "metadata": {},
   "source": [
    "## Training a predictive model on numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7836cb",
   "metadata": {},
   "source": [
    "`sklearn` works with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
    "\n",
    "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2e3e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
    "numerical_features.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69cbc57",
   "metadata": {},
   "source": [
    "Unfortunately some passengers do not have age information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d442e2f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "numerical_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386fe43",
   "metadata": {},
   "source": [
    "Let's use pandas to get the median value for the data we do have and then the `fillna` method to input the median age for those passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b18a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "median_features = numerical_features.dropna().median()\n",
    "median_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec631f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "imputed_features = numerical_features.fillna(median_features)\n",
    "imputed_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd2321",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "imputed_features.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c0096",
   "metadata": {},
   "source": [
    "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d304e8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features_array = imputed_features.values\n",
    "features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfda0d4",
   "metadata": {},
   "source": [
    "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45138798",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target_bool, test_size=0.20, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1370e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"feature_train:\".ljust(30), features_train.shape)\n",
    "print(\"feature_test:\".ljust(30), features_test.shape)\n",
    "print(\"target_train:\".ljust(30), target_train.shape)\n",
    "print(\"target_test:\".ljust(30), target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b44625",
   "metadata": {},
   "source": [
    "Let's start with a simple model from sklearn, `LogisticRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d340927",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_initial = LogisticRegression()\n",
    "logreg_initial.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbda334-6250-4db4-830f-a07f0b82b55f",
   "metadata": {},
   "source": [
    "The ```fit``` function trains the model using the features in our training set(```features_train```), and the expected prediction for each passenger (```target_train```). Now let's perform inference using using the records in our test set (```features_test```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e12ceb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target_predicted = logreg_initial.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44bccf-cffc-45fd-8baf-ed15f40295f4",
   "metadata": {},
   "source": [
    "In a lot of ML examples you'll see `targeted_predicted` named `y_hat`, which in statistics is written ŷ (technically a 'y' with a circumflex). This is the name for the \"predicted value of Y\" for regression equitions.\n",
    "\n",
    "Now we can compare our model's predictions with the actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc25c7a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103b52d",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* How does this compare with our baseline prediction of 61.6%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96096b8-5f1b-4634-bf8f-889c082cf618",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "In the previous section we trained('fit') a model and performed inference('predict') back to back. In many cases training takes a significant amount of time and then the model is saved and re-loaded for use later - potentially on different system(s).\n",
    "\n",
    "Let's save our LinearRegression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b258adb-0359-4582-b5a0-435c9350d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model for use later\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(logreg_initial,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec15e86-15e8-4cbc-8ded-892f2509c380",
   "metadata": {},
   "source": [
    "Check and see that the model was written out to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2016a9-cc63-46d4-a195-990faafc7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -lh model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb9daae-a402-4b4f-856b-f3f0bbfa19d5",
   "metadata": {},
   "source": [
    "Now let's read the model back in and use it to perform the prediction again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549efe5-cd8e-42c1-acdd-19b6d4c3c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model back in\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    logreg_reloaded = pickle.load(f)\n",
    "\n",
    "target_repredicted = logreg_reloaded.predict(features_test)\n",
    "accuracy_score(target_test, target_repredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a416d2d-e239-4827-8c88-3eb67ab2ca18",
   "metadata": {},
   "source": [
    "Let's try a different mix of the data set by re-splitting our dataset with a different ```random_state```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17942d17-5a53-40a0-81a8-585c9f7723b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_train, new_features_test, new_target_train, new_target_test = train_test_split(\n",
    "    features_array, target_bool, test_size=0.20, random_state=10)\n",
    "\n",
    "new_target_predicted = logreg_reloaded.predict(new_features_test)\n",
    "accuracy_score(new_target_test, new_target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60257e-4b18-4b6b-8ac5-78a508168cf0",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* What are some reasons why the accuracy is different between the two sets of feature_test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b88f1",
   "metadata": {},
   "source": [
    "## Model evaluation and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6218921",
   "metadata": {},
   "source": [
    "### Interpreting linear model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f4f47",
   "metadata": {},
   "source": [
    "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3295c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"coef:\", logreg_initial.coef_)\n",
    "\n",
    "x = np.arange(len(numerical_features.columns.values))\n",
    "plt.bar(numerical_features.columns.values, logreg_initial.coef_.ravel())\n",
    "_ = plt.xticks(numerical_features.columns.values, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced041e2",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* What does the importance of these features mean for the passengers of the Titanic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c8d2f",
   "metadata": {},
   "source": [
    "### Alternative evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1fe7e",
   "metadata": {},
   "source": [
    "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006b60f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target_predicted_proba = logreg_initial.predict_proba(features_test)\n",
    "target_predicted_proba[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e5922",
   "metadata": {},
   "source": [
    "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
    "\n",
    "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea756dc0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284a1d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(target_test, target_predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de569fe",
   "metadata": {},
   "source": [
    "Here the area under ROC curve is 0.722 which is very similar to the accuracy (0.732). The ROC-AUC score of a random model is expected to be 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance.\n",
    "\n",
    "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cd7c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(target_test, target_predicted, labels=logreg_initial.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=logreg_initial.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd93bf",
   "metadata": {},
   "source": [
    "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d3ce7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(target_test, target_predicted,\n",
    "                            target_names=['not survived', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6405a-35a4-4279-bd37-ef3a0b3934cb",
   "metadata": {},
   "source": [
    "Precision is the measure of the number of True Positives relative to the total number of Positive outcomes predicted: TP / (TP + FP).\n",
    "\n",
    "Recall is the measure of the number of True Positives relative to the number of ground truth Positives: TP / (TP + FN)\n",
    "\n",
    "F1-Score balances the Precision and Recall scores: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Support gives the number of how many of each kind of record were in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b6773",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c72883",
   "metadata": {},
   "source": [
    "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact on the estimated accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc05e6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target_bool, test_size=0.20, random_state=0)\n",
    "\n",
    "logreg_initial.fit(features_train, target_train).score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bb243",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target, test_size=0.20, random_state=1)\n",
    "\n",
    "logreg_initial.fit(features_train, target_train).score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7682406",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target, test_size=0.20, random_state=2)\n",
    "\n",
    "logreg_initial.fit(features_train, target_train).score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c1317",
   "metadata": {},
   "source": [
    "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5a070",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg_initial, features_array, target_bool, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbbc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15069730",
   "metadata": {},
   "source": [
    "`cross_val_score` reports accuracy by default but it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3d15f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "scores = cross_val_score(logreg_initial, features_array, target_bool, cv=3,\n",
    "                         scoring='roc_auc')\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710177b1",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "- Compute cross-validated scores for other classification metrics ('precision', 'recall', 'f1', 'accuracy'...).\n",
    "\n",
    "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
    "\n",
    "Hints:\n",
    "\n",
    "The list of classification metrics is available in the online documentation:\n",
    "\n",
    "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6895e5e",
   "metadata": {},
   "source": [
    "## More feature engineering and richer models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56dd99",
   "metadata": {},
   "source": [
    "Let us now try to build richer models by including more features as potential predictors for our model.\n",
    "\n",
    "Categorical variables such as `data.Embarked` or `data.Sex` can be converted as boolean indicators features also known as dummy variables or one-hot-encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc42bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data.Sex, prefix='Sex').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432172a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data.Embarked, prefix='Embarked').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b301bf6",
   "metadata": {},
   "source": [
    "We can combine those new numerical features with the previous features using `pandas.concat` along `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924ba48",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rich_features = pd.concat([data.get(['Fare', 'Age','Pclass']),\n",
    "                           pd.get_dummies(data.Sex, prefix='Sex'),\n",
    "                           pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
    "                          axis=1)\n",
    "rich_features.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e1f97",
   "metadata": {},
   "source": [
    "In this case, by construction the new `Sex_male` feature is redundant with `Sex_female`. Let's drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852285bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rich_features_no_male = rich_features.drop(columns='Sex_male', axis=1)\n",
    "rich_features_no_male.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be986095",
   "metadata": {},
   "source": [
    "Let us not forget to imput the median age for passengers without age information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182557d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rich_features_final = rich_features_no_male.fillna(rich_features_no_male.dropna().median())\n",
    "rich_features_final.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e4a4a",
   "metadata": {},
   "source": [
    "We can finally cross-validate a logistic regression model on this new data and observe that the mean score has significantly increased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a2530",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression(max_iter=225)\n",
    "scores = cross_val_score(logreg, rich_features_final, target_bool, cv=5, scoring='accuracy')\n",
    "print(scores.min(), scores.mean(), scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db94b4",
   "metadata": {},
   "source": [
    "Let's plot the weights for the features of this newly fitted logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab90c59-4e8d-4d01-883d-82dcc2e12d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(rich_features_final, target_bool)\n",
    "\n",
    "print(\"coef:\", logreg.coef_)\n",
    "\n",
    "x = np.arange(len(numerical_features.columns.values))\n",
    "plt.bar(rich_features_final.columns.values, logreg.coef_.ravel())\n",
    "_ = plt.xticks(rich_features_final.columns.values, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9205a-cbec-472f-846c-af8e428ea535",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* How do you interpret the importance of the new features?\n",
    "\n",
    "* Do you think this trained model would be accurate with newer data? e.g. passenger data from a ship that sank today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77541cd",
   "metadata": {},
   "source": [
    "### Training Non-linear models: ensembles of randomized trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbe39b",
   "metadata": {},
   "source": [
    "`sklearn` also implements non linear models that are known to perform very well for data-science projects where datasets don't have a huge number of features (e.g. less than 5000). A full list of `sklearn` supervised learning models can be found here: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "Let us have a look at Random Forests and Gradient Boosted Trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad396a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(rf, rich_features_final, target_bool, cv=5, n_jobs=4,\n",
    "                         scoring='accuracy')\n",
    "print(scores.min(), scores.mean(), scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec0ea1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                subsample=.8, max_features=.5)\n",
    "gb_scores = cross_val_score(gb, rich_features_final, target_bool, cv=5, n_jobs=4,\n",
    "                         scoring='accuracy')\n",
    "print(gb_scores.min(), gb_scores.mean(), gb_scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922a790",
   "metadata": {},
   "source": [
    "Both models seem to do slightly better than the logistic regression model on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565bfbc",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "- Change the value of the learning_rate and other `GradientBoostingClassifier` parameter, can you get a better mean score?\n",
    "\n",
    "- Would treating the `PClass` variable as categorical improve the models performance?\n",
    "\n",
    "- Find out which predictor variables (features) are the most informative for those models.\n",
    "\n",
    "Hints:\n",
    "\n",
    "Fitted ensembles of trees have `feature_importance_` attribute that can be used similarly to the `coef_` attribute of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a2ccb-d2dc-48c4-baca-c25018896040",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(rich_features_final, target)\n",
    "rf.feature_importances_\n",
    "rf_feature_importances = pd.DataFrame(rf.feature_importances_, index=rich_features_final.columns,  columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "x = np.arange(len(rich_features_final.columns))\n",
    "plt.bar(x, rf.feature_importances_.ravel())\n",
    "_ = plt.xticks(x, rich_features_final.columns, rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2921e3-09b0-43a2-b378-c709c7680b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(rich_features_final, target)\n",
    "gb.feature_importances_\n",
    "gb_feature_importances = pd.DataFrame(gb.feature_importances_, index=rich_features_final.columns,  columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "x = np.arange(len(rich_features_final.columns))\n",
    "plt.bar(x, gb.feature_importances_.ravel())\n",
    "_ = plt.xticks(x, rich_features_final.columns, rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee4841",
   "metadata": {},
   "source": [
    "## Automated parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b10a60",
   "metadata": {},
   "source": [
    "Instead of changing the value of the learning rate manually and re-running the cross-validation, we can find the best values for the parameters automatically (assuming we are willing to wait):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3203a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
    "gs.fit(rich_features_final, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c40682",
   "metadata": {},
   "source": [
    "Let us sort the models by mean validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284010e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04e904",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84511a4c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ef792",
   "metadata": {},
   "source": [
    "We should note that the mean scores are very close to one another and almost always within one standard deviation of one another. This means that all those parameters are quite reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a2010",
   "metadata": {},
   "source": [
    "## Avoiding data snooping with pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370238a",
   "metadata": {},
   "source": [
    "When doing imputation in pandas, prior to computing the train test split we use data from the test to improve the accuracy of the median value that we impute on the training set. This is actually cheating. To avoid this we should compute the median of the features on the training fold and use that median value to do the imputation both on the training and validation fold for a given CV split.\n",
    "\n",
    "To do this we can prepare the features as previously but without the imputation: we just replace missing values by the -1 marker value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56344828",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features = pd.concat([data.get(['Fare', 'Age', 'Pclass']),\n",
    "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
    "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
    "                     axis=1)\n",
    "features = features.drop(columns='Sex_male', axis=1)\n",
    "\n",
    "# Because of the following bug we cannot use NaN as the missing\n",
    "# value marker, use a negative value as marker instead:\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/3044\n",
    "features = features.fillna(-1)\n",
    "features.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9119a1",
   "metadata": {},
   "source": [
    "We can now use the `Imputer` transformer of scikit-learn to find the median value on the training set and apply it on missing values of both the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e1a6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(features.values, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcbd3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median', missing_values=-1)\n",
    "\n",
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c1e61",
   "metadata": {},
   "source": [
    "The median age computed on the training set is stored in the `statistics_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cd73e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Median age of full set:\".ljust(30), median_features['Age'])\n",
    "print(\"Median age of training set:\".ljust(30), imputer.statistics_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d9a80",
   "metadata": {},
   "source": [
    "Imputation can now happen by calling  the transform method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978627b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f25b2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.any(X_train == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e9955",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.any(X_train_imputed == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf13a79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.any(X_test == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7fb961",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.any(X_test_imputed == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd0f3b",
   "metadata": {},
   "source": [
    "We can now use a pipeline that wraps an imputer transformer and the classifier itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8268d5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imputer = SimpleImputer(strategy='median', missing_values=-1)\n",
    "\n",
    "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                        subsample=.8, max_features=.5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imp', imputer),\n",
    "    ('clf', classifier),\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipeline, features.values, target, cv=5, n_jobs=4,\n",
    "                         scoring='accuracy', )\n",
    "print(\"Scores with Snooping:\".ljust(25), gb_scores.min(), gb_scores.mean(), gb_scores.max())\n",
    "print(\"Scores without Snooping:\".ljust(25), scores.min(), scores.mean(), scores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af51be",
   "metadata": {},
   "source": [
    "The mean cross-validation is slightly lower than when we used the imputation on the whole data as we did earlier although not by much. This means that in this case the data-snooping was not really helping the model cheat by much.\n",
    "\n",
    "Let us re-run the grid search, this time on the pipeline. Note that thanks to the pipeline structure we can optimize the interaction of the imputation method with the parameters of the downstream classifier without cheating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd26fb5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'imp__strategy': ['mean', 'median'],\n",
    "    'clf__max_features': [0.5, 1],\n",
    "    'clf__max_depth': [3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
    "gs.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea565b38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5685c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53644e91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c509f",
   "metadata": {},
   "source": [
    "From this search we can conclude the best imputation strategy and tuning parameters when training a GBRT model on this data given the parameter search space we defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4686e5-0efa-478e-afa0-e1a8819350f5",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "The AI Ecosystem is evolving quickly! There is a huge number of tools available some gaining favor, some losing favor. Even individual tools are being updated constantly and documentation and examples you find that are even 1 year old may be out of date and no longer work correctly with current versions of a toolchain you install.\n",
    "\n",
    "Also, don't expect one model to do everything! Break down the problem you're trying to solve and have different models for different steps. This is a common practice and is called building an 'Ensemble.' In the\n",
    "\n",
    "The most important thing is to understand the fundementals, know what to look for to make sure your model is performing well and to avoid common pitfalls -- and, finally, don't be afraid to try something different. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d839b",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "Many thanks to:\n",
    "\n",
    "- Adam Walz for providing the original version of this notebook https://github.com/adamwalz/Jupyter-Notebooks\n",
    "\n",
    "Adam thanks:\n",
    "\n",
    "- Kaggle for setting up the Titanic challenge.\n",
    "\n",
    "- This blog post by Philippe Adjiman for inspiration:\n",
    "\n",
    "http://www.philippeadjiman.com/blog/2013/09/12/a-data-science-exploration-from-the-titanic-in-r/\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- Andrew Ng\n",
    "  - https://www.coursera.org/learn/ai-for-everyone\n",
    "  - https://deeplearning.ai\n",
    "\n",
    "\n",
    "- Data Science Challenge Websites / Places To Find Example Datasets\n",
    "  - https://kaggle.com\n",
    "  - https://www.drivendata.org\n",
    "  - https://competitions.codalab.org/competitions/\n",
    "  - https://machinehack.com/hackathons\n",
    "  - https://tianchi.aliyun.com/competition/gameList/activeList\n",
    "\n",
    "\n",
    "- AutoML\n",
    "  - https://neptune.ai/blog/a-quickstart-guide-to-auto-sklearn-automl-for-machine-learning-practitioners\n",
    "\n",
    "\n",
    "- Examples of Specific Kinds of Data Science Challenges\n",
    "  - Image Segmentation\n",
    "    - [Open Images Instance Segmentation RVC 2020 edition | Kaggle](https://www.kaggle.com/competitions/open-images-instance-segmentation-rvc-2020)\n",
    "    - [DanceTrack : Tracking Multiple Objects in Uniform Appearance & Diverse Motion | CodaLab](https://competitions.codalab.org/competitions/35786)\n",
    "  - Image Classification\n",
    "    - [Conser-vision Practice Area: Image Classification | DrivenData](https://www.drivendata.org/competitions/87/competition-image-classification-wildlife-conservation/)\n",
    "    - [Petals to the Metal - Flower Classification on TPU | Kaggle](https://www.kaggle.com/competitions/tpu-getting-started/overview/description)\n",
    "  - Natural Language Processing\n",
    "    - [Natural Language Processing with Disaster Tweets | Kaggle](https://www.kaggle.com/competitions/nlp-getting-started/overview/description)\n",
    "    - [Build a complex Named Entity Recognition System for 11 languages | CodaLab](https://competitions.codalab.org/competitions/36425)\n",
    "    - [Sentiment Analysis: Weekend Hackathon Edition #2 — The Last Hacker Standing | Machine Hack](https://machinehack.com/hackathons/sentiment_analysis_weekend_hackathon_edition_2_the_last_hacker_standing/overview)\n",
    "  - Prediction\n",
    "    - [Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines | Driven Data](https://www.drivendata.org/competitions/66/flu-shot-learning/)\n",
    "  - Generative Adversarial Networks\n",
    "    - [I’m Something of a Painter Myself | Kaggle](https://www.kaggle.com/competitions/gan-getting-started)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
